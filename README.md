# LLM Security Scanner

Scan any **public GitHub repository** for security issues using a free **Hugging Face Inference** model.  
Results are presented in a clean, GitHub-like interface:

- **Issues View** â€” severity labels, filters, deep links to GitHub
- **Code View** â€” Monaco editor with **persistent line highlight** and a focused **10-line snippet**
- **Quick Fixes** â€” 1â€“2 pragmatic suggestions per issue generated by the model

---

## ğŸ”— Live Link (add later)

**https://your-domain.vercel.app** *(coming soon â€” add your Vercel URL here)*

---

## âœ¨ Features

- **Hugging Faceâ€“powered analysis** (no paid services required)
- **Commit-pinned scans** (reproducible, deep-linkable)
- **GitHub-like UI**: issue list + code viewer with always-on highlight
- **Quick Fix** suggestions: minimal changes you can apply with confidence
- **In-memory cache** keyed by `repo@commit` for snappy local runs

---

## ğŸ§± Tech Stack

- **Framework**: Next.js (App Router), React 18, TypeScript, Tailwind, lucide-react
- **Editor**: `@monaco-editor/react` (Monaco)
- **GitHub API**: Octokit REST
- **LLM**: Hugging Face Inference (e.g., `Qwen/Qwen2.5-Coder-1.5B-Instruct`)

---

## ğŸ—‚ï¸ Project Structure

app/
api/
file/route.ts # fetch raw file contents
fix/route.ts # LLM quick-fix suggestions (Hugging Face)
scan/route.ts # run scan & cache results
components/ # Header, IssuesList, CodeViewer, SuggestPanel, etc.
layout.tsx
page.tsx
globals.css
lib/
github.ts # list tree, get file, resolve commit
llm.ts # calls Hugging Face Inference
rules.ts # (helpers for hinting/labels; model does the heavy lifting)
store.ts # in-memory storage
types.ts # zod schemas & types

yaml
Copy code

---

## ğŸ§ª Quickstart (Run Locally)

### 1) Requirements
- **Node.js 18+** (18/20 LTS recommended)
- **npm** (or pnpm/yarn)

### 2) Install
```bash
npm install
3) Environment
Create .env.local in the project root and add:

Key	Purpose	Example
GITHUB_TOKEN	Avoid GitHub API rate limits (optional)	ghp_...
LLM_PROVIDER	Must be hf	hf
HUGGINGFACE_API_KEY	Required for Hugging Face Inference	hf_xxx
HF_MODEL	Model id	Qwen/Qwen2.5-Coder-1.5B-Instruct
SCAN_STRICT_DIRS	Restrict to first-party dirs (true/false)	false
MAX_FILES	Max files to scan	80
MAX_BYTES_PER_FILE	Per-file byte cap	120000

Example .env.local:

ini
Copy code
# Optional but helpful for rate limits
GITHUB_TOKEN=

# Hugging Face configuration (required)
LLM_PROVIDER=hf
HUGGINGFACE_API_KEY=
HF_MODEL=Qwen/Qwen2.5-Coder-1.5B-Instruct

# Scanner tuning
SCAN_STRICT_DIRS=false
MAX_FILES=80
MAX_BYTES_PER_FILE=120000
4) Start Dev Server
bash
Copy code
npm run dev
# open http://localhost:3000
5) Use It
Enter a repository like vercel/next.js and click Scan.

Browse Issues (filter by severity or search text).

Click View code to open Monaco with:

persistent yellow highlight on the issue line(s)

a 10-line context window and real file line numbers

Check Quick Fixes beneath the code for 1â€“2 suggested changes from the model.

ğŸš€ Deploy on Vercel
bash
Copy code
npm i -g vercel
vercel login
vercel link --yes --name seclens   # or your preferred name

# Add environment variables (Production); repeat for Preview if desired
vercel env add GITHUB_TOKEN production
vercel env add LLM_PROVIDER production           # set to: hf
vercel env add HUGGINGFACE_API_KEY production
vercel env add HF_MODEL production               # e.g. Qwen/Qwen2.5-Coder-1.5B-Instruct
vercel env add SCAN_STRICT_DIRS production       # false
vercel env add MAX_FILES production              # 80
vercel env add MAX_BYTES_PER_FILE production     # 120000

# Deploy (preview then prod)
vercel --yes --name seclens
vercel --prod --yes --name seclens
ğŸ§° Troubleshooting
GitHub API 403 / rate limits
Add a free GITHUB_TOKEN to .env.local, restart the dev server.

No findings on some repos
Check the Scan summary card:

filesConsidered = 0: relax filters (SCAN_STRICT_DIRS=false) or broaden allowed extensions in lib/github.ts.

filesScanned > 0 but findings = 0: try a different repo or model; raise MAX_FILES if needed.

Highlight not visible
Ensure youâ€™re using the provided CodeViewer.tsx and CSS highlight rules in app/globals.css. The highlight is persistent and also marks the gutter/ruler.

ğŸ”­ Future Prospects
Accuracy & Signal

Expand model prompts for deeper taint analysis & context windows

Add provider-specific rules as prompting hints (SQLi/SSRF/path traversal/XXE/JWT/secret types)

Lightweight embeddings to cluster & dedupe similar findings

Developer UX

â€œPropose fixâ€ â†’ show unified diff (Monaco Diff / react-diff-viewer-continued)

â€œCreate PRâ€ flow via GitHub API

Per-scan ignore patterns & a simple settings pane (file globs, caps, directories)

Performance & Scale

Background scans via Vercel Background Functions or Upstash QStash

GitHub ETags / If-None-Match, exponential backoff

Incremental UI: stream issues as theyâ€™re found

Smarter chunking & concurrency for model calls

Security & Ops

GitHub OAuth to enable private repo scans

Sentry for error tracking & basic metrics (duration, files scanned)

Redact secrets in UI/logs by default

âš ï¸ Disclaimer
This tool assists security reviews and may surface false positives/negatives. Always validate findings before applying changes.

ğŸ“„ License
MIT (or your preferred license). Add a LICENSE file if open-sourcing.

ğŸ™Œ Credits
Next.js, Monaco Editor, Tailwind, Octokit

LLM analysis & quick fixes via Hugging Face Inference
